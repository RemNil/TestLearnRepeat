[
["ema-approved-medicines.html", "1 EMA approved medicines 1.1 Approvals per therapeutic area 1.2 Past regulatory applications", " 1 EMA approved medicines How do we figure out how many clinical trials likely failed due to bad methodological design? If you have any idea or suggestion, please leave a comment using the annotation function on this website. In a Stream Graph (Byron and Wattenberg 2008), the volume of individual streams is proportional to the values in each category (i.e. number of approvals per year). This plot might be useful to quickly assess “trends” in approval rate per therapeutic area over time. For instance, if you hover over the graph, you will quickly discover that there were quite disproportionately many approvals for Arthritis lately. Shown are therapeutic indications mentioned in EPARS (Papathanasiou et al. 2016). Data freeze: 25. November 2019. 1.1 Approvals per therapeutic area If you are more interested in “exact numbers, then here is a donut plot of the same data with a focus on the most active therapeutic areas. Note, however that the”therapeutic areas\" are not necessarily on the same level of abstraction in disease ontology. All data comes with absolutely no warranty. 1.2 Past regulatory applications With increasing experience on CTAs or INDs, there may be associations between “success” metrics and certain formal characteristics of application materials. According to BfArM there are 3,647 CTA application for 2014-2018 in Germany and according to EMA there are 132,700 CTA applications submitted to the EudraCT database in total. Unfortunately, as Wong, Siah, and Lo (2019) have demonstrated that the estimation of “success rate” is not without sophisticated complexities. The most dramatic barrier is that the actual data is behind paywalls, which severely limits research ethicists like me who suffer from scarce resources and high academic pressure to produce findings that “sell”. For further information, please refer directly to source of origin: Pei 2019. References "]
]
